{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=torch.zeros((27,27),dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi={s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos={i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b={}\n",
    "# for w in words:\n",
    "#     name=['<S>']+list(w)+['<E>']\n",
    "#     for x,y in zip(name,name[1:]):\n",
    "#         b[(x,y)]=b.get((x,y),0) + 1\n",
    "for w in words:\n",
    "    name=['.']+list(w)+['.']\n",
    "    for x,y in zip(name,name[1:]):\n",
    "        N[stoi[x],stoi[y]]+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(b.items(),key=lambda kv:-kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19daad063d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(N,cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN approch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys=[],[]\n",
    "for w in words[:1]:\n",
    "    name=['.']+list(w)+['.']\n",
    "    for x,y in zip(name,name[1:]):\n",
    "        xs.append(stoi[x])\n",
    "        ys.append(stoi[y])\n",
    "xs=torch.tensor(xs)\n",
    "ys=torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc=torch.nn.functional.one_hot(xs,num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x274ee9d71d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially what we are doing is we are taking input layer of 27 and we are sending one hot vector at a single round. so shape of w for single neuron is 27 * 1 and we are taking 27 neurons in hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.randn((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4202,  0.2082,  0.1716,  1.0313, -1.0565,  0.0907,  0.8835,  0.8459,\n",
       "         -0.1742,  1.1272,  1.1499,  0.9338,  0.0811,  0.1836,  0.7221, -0.6086,\n",
       "          0.2446, -1.0480,  0.2273, -0.7793, -0.8747,  1.2098, -1.0722,  0.2030,\n",
       "          0.9666,  0.8442,  0.0192]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=counts/counts.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.2090)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(5),ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proper NN flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  5, 13, 13,  1]) tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "print(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise weights and set xs and ys\n",
    "W=torch.randn((27,27),requires_grad=True)\n",
    "X=torch.nn.functional.one_hot(xs,num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "logits=X @ W\n",
    "counts=logits.exp()\n",
    "probs=counts/counts.sum(1,keepdim=True)\n",
    "loss=-probs[torch.arange(5),ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2088, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward pass\n",
    "W.grad=None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update weights based off backward prop\n",
    "W.data+=-0.1*W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear Imple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys=[],[]\n",
    "for w in words:\n",
    "    name=['.']+list(w)+['.']\n",
    "    for x,y in zip(name,name[1:]):\n",
    "        xs.append(stoi[x])\n",
    "        ys.append(stoi[y])\n",
    "xs=torch.tensor(xs)\n",
    "ys=torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise weights and set xs and ys\n",
    "W=torch.randn((27,27),requires_grad=True)\n",
    "X=torch.nn.functional.one_hot(xs,num_classes=27).float()\n",
    "num=xs.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # forward pass\n",
    "# logits=X @ W\n",
    "# counts=logits.exp()\n",
    "# probs=counts/counts.sum(1,keepdim=True)\n",
    "# loss=-probs[torch.arange(num),ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #backward pass\n",
    "# W.grad=None\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #update weights based off backward prop\n",
    "# W.data+=-0.1*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5649, grad_fn=<NegBackward0>)\n",
      "tensor(2.5638, grad_fn=<NegBackward0>)\n",
      "tensor(2.5627, grad_fn=<NegBackward0>)\n",
      "tensor(2.5617, grad_fn=<NegBackward0>)\n",
      "tensor(2.5606, grad_fn=<NegBackward0>)\n",
      "tensor(2.5596, grad_fn=<NegBackward0>)\n",
      "tensor(2.5586, grad_fn=<NegBackward0>)\n",
      "tensor(2.5576, grad_fn=<NegBackward0>)\n",
      "tensor(2.5566, grad_fn=<NegBackward0>)\n",
      "tensor(2.5557, grad_fn=<NegBackward0>)\n",
      "tensor(2.5548, grad_fn=<NegBackward0>)\n",
      "tensor(2.5538, grad_fn=<NegBackward0>)\n",
      "tensor(2.5529, grad_fn=<NegBackward0>)\n",
      "tensor(2.5520, grad_fn=<NegBackward0>)\n",
      "tensor(2.5512, grad_fn=<NegBackward0>)\n",
      "tensor(2.5503, grad_fn=<NegBackward0>)\n",
      "tensor(2.5495, grad_fn=<NegBackward0>)\n",
      "tensor(2.5486, grad_fn=<NegBackward0>)\n",
      "tensor(2.5478, grad_fn=<NegBackward0>)\n",
      "tensor(2.5470, grad_fn=<NegBackward0>)\n",
      "tensor(2.5462, grad_fn=<NegBackward0>)\n",
      "tensor(2.5454, grad_fn=<NegBackward0>)\n",
      "tensor(2.5446, grad_fn=<NegBackward0>)\n",
      "tensor(2.5439, grad_fn=<NegBackward0>)\n",
      "tensor(2.5431, grad_fn=<NegBackward0>)\n",
      "tensor(2.5424, grad_fn=<NegBackward0>)\n",
      "tensor(2.5417, grad_fn=<NegBackward0>)\n",
      "tensor(2.5409, grad_fn=<NegBackward0>)\n",
      "tensor(2.5402, grad_fn=<NegBackward0>)\n",
      "tensor(2.5395, grad_fn=<NegBackward0>)\n",
      "tensor(2.5389, grad_fn=<NegBackward0>)\n",
      "tensor(2.5382, grad_fn=<NegBackward0>)\n",
      "tensor(2.5375, grad_fn=<NegBackward0>)\n",
      "tensor(2.5369, grad_fn=<NegBackward0>)\n",
      "tensor(2.5362, grad_fn=<NegBackward0>)\n",
      "tensor(2.5356, grad_fn=<NegBackward0>)\n",
      "tensor(2.5349, grad_fn=<NegBackward0>)\n",
      "tensor(2.5343, grad_fn=<NegBackward0>)\n",
      "tensor(2.5337, grad_fn=<NegBackward0>)\n",
      "tensor(2.5331, grad_fn=<NegBackward0>)\n",
      "tensor(2.5325, grad_fn=<NegBackward0>)\n",
      "tensor(2.5319, grad_fn=<NegBackward0>)\n",
      "tensor(2.5313, grad_fn=<NegBackward0>)\n",
      "tensor(2.5307, grad_fn=<NegBackward0>)\n",
      "tensor(2.5302, grad_fn=<NegBackward0>)\n",
      "tensor(2.5296, grad_fn=<NegBackward0>)\n",
      "tensor(2.5291, grad_fn=<NegBackward0>)\n",
      "tensor(2.5285, grad_fn=<NegBackward0>)\n",
      "tensor(2.5280, grad_fn=<NegBackward0>)\n",
      "tensor(2.5274, grad_fn=<NegBackward0>)\n",
      "tensor(2.5269, grad_fn=<NegBackward0>)\n",
      "tensor(2.5264, grad_fn=<NegBackward0>)\n",
      "tensor(2.5259, grad_fn=<NegBackward0>)\n",
      "tensor(2.5254, grad_fn=<NegBackward0>)\n",
      "tensor(2.5249, grad_fn=<NegBackward0>)\n",
      "tensor(2.5244, grad_fn=<NegBackward0>)\n",
      "tensor(2.5239, grad_fn=<NegBackward0>)\n",
      "tensor(2.5234, grad_fn=<NegBackward0>)\n",
      "tensor(2.5229, grad_fn=<NegBackward0>)\n",
      "tensor(2.5225, grad_fn=<NegBackward0>)\n",
      "tensor(2.5220, grad_fn=<NegBackward0>)\n",
      "tensor(2.5215, grad_fn=<NegBackward0>)\n",
      "tensor(2.5211, grad_fn=<NegBackward0>)\n",
      "tensor(2.5206, grad_fn=<NegBackward0>)\n",
      "tensor(2.5202, grad_fn=<NegBackward0>)\n",
      "tensor(2.5198, grad_fn=<NegBackward0>)\n",
      "tensor(2.5193, grad_fn=<NegBackward0>)\n",
      "tensor(2.5189, grad_fn=<NegBackward0>)\n",
      "tensor(2.5185, grad_fn=<NegBackward0>)\n",
      "tensor(2.5180, grad_fn=<NegBackward0>)\n",
      "tensor(2.5176, grad_fn=<NegBackward0>)\n",
      "tensor(2.5172, grad_fn=<NegBackward0>)\n",
      "tensor(2.5168, grad_fn=<NegBackward0>)\n",
      "tensor(2.5164, grad_fn=<NegBackward0>)\n",
      "tensor(2.5160, grad_fn=<NegBackward0>)\n",
      "tensor(2.5156, grad_fn=<NegBackward0>)\n",
      "tensor(2.5152, grad_fn=<NegBackward0>)\n",
      "tensor(2.5149, grad_fn=<NegBackward0>)\n",
      "tensor(2.5145, grad_fn=<NegBackward0>)\n",
      "tensor(2.5141, grad_fn=<NegBackward0>)\n",
      "tensor(2.5137, grad_fn=<NegBackward0>)\n",
      "tensor(2.5134, grad_fn=<NegBackward0>)\n",
      "tensor(2.5130, grad_fn=<NegBackward0>)\n",
      "tensor(2.5126, grad_fn=<NegBackward0>)\n",
      "tensor(2.5123, grad_fn=<NegBackward0>)\n",
      "tensor(2.5119, grad_fn=<NegBackward0>)\n",
      "tensor(2.5116, grad_fn=<NegBackward0>)\n",
      "tensor(2.5112, grad_fn=<NegBackward0>)\n",
      "tensor(2.5109, grad_fn=<NegBackward0>)\n",
      "tensor(2.5106, grad_fn=<NegBackward0>)\n",
      "tensor(2.5102, grad_fn=<NegBackward0>)\n",
      "tensor(2.5099, grad_fn=<NegBackward0>)\n",
      "tensor(2.5096, grad_fn=<NegBackward0>)\n",
      "tensor(2.5093, grad_fn=<NegBackward0>)\n",
      "tensor(2.5089, grad_fn=<NegBackward0>)\n",
      "tensor(2.5086, grad_fn=<NegBackward0>)\n",
      "tensor(2.5083, grad_fn=<NegBackward0>)\n",
      "tensor(2.5080, grad_fn=<NegBackward0>)\n",
      "tensor(2.5077, grad_fn=<NegBackward0>)\n",
      "tensor(2.5074, grad_fn=<NegBackward0>)\n",
      "tensor(2.5071, grad_fn=<NegBackward0>)\n",
      "tensor(2.5068, grad_fn=<NegBackward0>)\n",
      "tensor(2.5065, grad_fn=<NegBackward0>)\n",
      "tensor(2.5062, grad_fn=<NegBackward0>)\n",
      "tensor(2.5059, grad_fn=<NegBackward0>)\n",
      "tensor(2.5056, grad_fn=<NegBackward0>)\n",
      "tensor(2.5053, grad_fn=<NegBackward0>)\n",
      "tensor(2.5051, grad_fn=<NegBackward0>)\n",
      "tensor(2.5048, grad_fn=<NegBackward0>)\n",
      "tensor(2.5045, grad_fn=<NegBackward0>)\n",
      "tensor(2.5042, grad_fn=<NegBackward0>)\n",
      "tensor(2.5040, grad_fn=<NegBackward0>)\n",
      "tensor(2.5037, grad_fn=<NegBackward0>)\n",
      "tensor(2.5034, grad_fn=<NegBackward0>)\n",
      "tensor(2.5032, grad_fn=<NegBackward0>)\n",
      "tensor(2.5029, grad_fn=<NegBackward0>)\n",
      "tensor(2.5027, grad_fn=<NegBackward0>)\n",
      "tensor(2.5024, grad_fn=<NegBackward0>)\n",
      "tensor(2.5022, grad_fn=<NegBackward0>)\n",
      "tensor(2.5019, grad_fn=<NegBackward0>)\n",
      "tensor(2.5017, grad_fn=<NegBackward0>)\n",
      "tensor(2.5014, grad_fn=<NegBackward0>)\n",
      "tensor(2.5012, grad_fn=<NegBackward0>)\n",
      "tensor(2.5009, grad_fn=<NegBackward0>)\n",
      "tensor(2.5007, grad_fn=<NegBackward0>)\n",
      "tensor(2.5004, grad_fn=<NegBackward0>)\n",
      "tensor(2.5002, grad_fn=<NegBackward0>)\n",
      "tensor(2.5000, grad_fn=<NegBackward0>)\n",
      "tensor(2.4998, grad_fn=<NegBackward0>)\n",
      "tensor(2.4995, grad_fn=<NegBackward0>)\n",
      "tensor(2.4993, grad_fn=<NegBackward0>)\n",
      "tensor(2.4991, grad_fn=<NegBackward0>)\n",
      "tensor(2.4989, grad_fn=<NegBackward0>)\n",
      "tensor(2.4986, grad_fn=<NegBackward0>)\n",
      "tensor(2.4984, grad_fn=<NegBackward0>)\n",
      "tensor(2.4982, grad_fn=<NegBackward0>)\n",
      "tensor(2.4980, grad_fn=<NegBackward0>)\n",
      "tensor(2.4978, grad_fn=<NegBackward0>)\n",
      "tensor(2.4976, grad_fn=<NegBackward0>)\n",
      "tensor(2.4974, grad_fn=<NegBackward0>)\n",
      "tensor(2.4971, grad_fn=<NegBackward0>)\n",
      "tensor(2.4969, grad_fn=<NegBackward0>)\n",
      "tensor(2.4967, grad_fn=<NegBackward0>)\n",
      "tensor(2.4965, grad_fn=<NegBackward0>)\n",
      "tensor(2.4963, grad_fn=<NegBackward0>)\n",
      "tensor(2.4961, grad_fn=<NegBackward0>)\n",
      "tensor(2.4959, grad_fn=<NegBackward0>)\n",
      "tensor(2.4958, grad_fn=<NegBackward0>)\n",
      "tensor(2.4956, grad_fn=<NegBackward0>)\n",
      "tensor(2.4954, grad_fn=<NegBackward0>)\n",
      "tensor(2.4952, grad_fn=<NegBackward0>)\n",
      "tensor(2.4950, grad_fn=<NegBackward0>)\n",
      "tensor(2.4948, grad_fn=<NegBackward0>)\n",
      "tensor(2.4946, grad_fn=<NegBackward0>)\n",
      "tensor(2.4944, grad_fn=<NegBackward0>)\n",
      "tensor(2.4943, grad_fn=<NegBackward0>)\n",
      "tensor(2.4941, grad_fn=<NegBackward0>)\n",
      "tensor(2.4939, grad_fn=<NegBackward0>)\n",
      "tensor(2.4937, grad_fn=<NegBackward0>)\n",
      "tensor(2.4935, grad_fn=<NegBackward0>)\n",
      "tensor(2.4934, grad_fn=<NegBackward0>)\n",
      "tensor(2.4932, grad_fn=<NegBackward0>)\n",
      "tensor(2.4930, grad_fn=<NegBackward0>)\n",
      "tensor(2.4929, grad_fn=<NegBackward0>)\n",
      "tensor(2.4927, grad_fn=<NegBackward0>)\n",
      "tensor(2.4925, grad_fn=<NegBackward0>)\n",
      "tensor(2.4923, grad_fn=<NegBackward0>)\n",
      "tensor(2.4922, grad_fn=<NegBackward0>)\n",
      "tensor(2.4920, grad_fn=<NegBackward0>)\n",
      "tensor(2.4919, grad_fn=<NegBackward0>)\n",
      "tensor(2.4917, grad_fn=<NegBackward0>)\n",
      "tensor(2.4915, grad_fn=<NegBackward0>)\n",
      "tensor(2.4914, grad_fn=<NegBackward0>)\n",
      "tensor(2.4912, grad_fn=<NegBackward0>)\n",
      "tensor(2.4911, grad_fn=<NegBackward0>)\n",
      "tensor(2.4909, grad_fn=<NegBackward0>)\n",
      "tensor(2.4908, grad_fn=<NegBackward0>)\n",
      "tensor(2.4906, grad_fn=<NegBackward0>)\n",
      "tensor(2.4905, grad_fn=<NegBackward0>)\n",
      "tensor(2.4903, grad_fn=<NegBackward0>)\n",
      "tensor(2.4902, grad_fn=<NegBackward0>)\n",
      "tensor(2.4900, grad_fn=<NegBackward0>)\n",
      "tensor(2.4899, grad_fn=<NegBackward0>)\n",
      "tensor(2.4897, grad_fn=<NegBackward0>)\n",
      "tensor(2.4896, grad_fn=<NegBackward0>)\n",
      "tensor(2.4894, grad_fn=<NegBackward0>)\n",
      "tensor(2.4893, grad_fn=<NegBackward0>)\n",
      "tensor(2.4891, grad_fn=<NegBackward0>)\n",
      "tensor(2.4890, grad_fn=<NegBackward0>)\n",
      "tensor(2.4889, grad_fn=<NegBackward0>)\n",
      "tensor(2.4887, grad_fn=<NegBackward0>)\n",
      "tensor(2.4886, grad_fn=<NegBackward0>)\n",
      "tensor(2.4885, grad_fn=<NegBackward0>)\n",
      "tensor(2.4883, grad_fn=<NegBackward0>)\n",
      "tensor(2.4882, grad_fn=<NegBackward0>)\n",
      "tensor(2.4881, grad_fn=<NegBackward0>)\n",
      "tensor(2.4879, grad_fn=<NegBackward0>)\n",
      "tensor(2.4878, grad_fn=<NegBackward0>)\n",
      "tensor(2.4877, grad_fn=<NegBackward0>)\n",
      "tensor(2.4875, grad_fn=<NegBackward0>)\n",
      "tensor(2.4874, grad_fn=<NegBackward0>)\n",
      "tensor(2.4873, grad_fn=<NegBackward0>)\n",
      "tensor(2.4871, grad_fn=<NegBackward0>)\n",
      "tensor(2.4870, grad_fn=<NegBackward0>)\n",
      "tensor(2.4869, grad_fn=<NegBackward0>)\n",
      "tensor(2.4868, grad_fn=<NegBackward0>)\n",
      "tensor(2.4866, grad_fn=<NegBackward0>)\n",
      "tensor(2.4865, grad_fn=<NegBackward0>)\n",
      "tensor(2.4864, grad_fn=<NegBackward0>)\n",
      "tensor(2.4863, grad_fn=<NegBackward0>)\n",
      "tensor(2.4862, grad_fn=<NegBackward0>)\n",
      "tensor(2.4860, grad_fn=<NegBackward0>)\n",
      "tensor(2.4859, grad_fn=<NegBackward0>)\n",
      "tensor(2.4858, grad_fn=<NegBackward0>)\n",
      "tensor(2.4857, grad_fn=<NegBackward0>)\n",
      "tensor(2.4856, grad_fn=<NegBackward0>)\n",
      "tensor(2.4855, grad_fn=<NegBackward0>)\n",
      "tensor(2.4853, grad_fn=<NegBackward0>)\n",
      "tensor(2.4852, grad_fn=<NegBackward0>)\n",
      "tensor(2.4851, grad_fn=<NegBackward0>)\n",
      "tensor(2.4850, grad_fn=<NegBackward0>)\n",
      "tensor(2.4849, grad_fn=<NegBackward0>)\n",
      "tensor(2.4848, grad_fn=<NegBackward0>)\n",
      "tensor(2.4847, grad_fn=<NegBackward0>)\n",
      "tensor(2.4846, grad_fn=<NegBackward0>)\n",
      "tensor(2.4845, grad_fn=<NegBackward0>)\n",
      "tensor(2.4844, grad_fn=<NegBackward0>)\n",
      "tensor(2.4842, grad_fn=<NegBackward0>)\n",
      "tensor(2.4841, grad_fn=<NegBackward0>)\n",
      "tensor(2.4840, grad_fn=<NegBackward0>)\n",
      "tensor(2.4839, grad_fn=<NegBackward0>)\n",
      "tensor(2.4838, grad_fn=<NegBackward0>)\n",
      "tensor(2.4837, grad_fn=<NegBackward0>)\n",
      "tensor(2.4836, grad_fn=<NegBackward0>)\n",
      "tensor(2.4835, grad_fn=<NegBackward0>)\n",
      "tensor(2.4834, grad_fn=<NegBackward0>)\n",
      "tensor(2.4833, grad_fn=<NegBackward0>)\n",
      "tensor(2.4832, grad_fn=<NegBackward0>)\n",
      "tensor(2.4831, grad_fn=<NegBackward0>)\n",
      "tensor(2.4830, grad_fn=<NegBackward0>)\n",
      "tensor(2.4829, grad_fn=<NegBackward0>)\n",
      "tensor(2.4828, grad_fn=<NegBackward0>)\n",
      "tensor(2.4827, grad_fn=<NegBackward0>)\n",
      "tensor(2.4826, grad_fn=<NegBackward0>)\n",
      "tensor(2.4825, grad_fn=<NegBackward0>)\n",
      "tensor(2.4824, grad_fn=<NegBackward0>)\n",
      "tensor(2.4823, grad_fn=<NegBackward0>)\n",
      "tensor(2.4823, grad_fn=<NegBackward0>)\n",
      "tensor(2.4822, grad_fn=<NegBackward0>)\n",
      "tensor(2.4821, grad_fn=<NegBackward0>)\n",
      "tensor(2.4820, grad_fn=<NegBackward0>)\n",
      "tensor(2.4819, grad_fn=<NegBackward0>)\n",
      "tensor(2.4818, grad_fn=<NegBackward0>)\n",
      "tensor(2.4817, grad_fn=<NegBackward0>)\n",
      "tensor(2.4816, grad_fn=<NegBackward0>)\n",
      "tensor(2.4815, grad_fn=<NegBackward0>)\n",
      "tensor(2.4814, grad_fn=<NegBackward0>)\n",
      "tensor(2.4813, grad_fn=<NegBackward0>)\n",
      "tensor(2.4813, grad_fn=<NegBackward0>)\n",
      "tensor(2.4812, grad_fn=<NegBackward0>)\n",
      "tensor(2.4811, grad_fn=<NegBackward0>)\n",
      "tensor(2.4810, grad_fn=<NegBackward0>)\n",
      "tensor(2.4809, grad_fn=<NegBackward0>)\n",
      "tensor(2.4808, grad_fn=<NegBackward0>)\n",
      "tensor(2.4807, grad_fn=<NegBackward0>)\n",
      "tensor(2.4807, grad_fn=<NegBackward0>)\n",
      "tensor(2.4806, grad_fn=<NegBackward0>)\n",
      "tensor(2.4805, grad_fn=<NegBackward0>)\n",
      "tensor(2.4804, grad_fn=<NegBackward0>)\n",
      "tensor(2.4803, grad_fn=<NegBackward0>)\n",
      "tensor(2.4802, grad_fn=<NegBackward0>)\n",
      "tensor(2.4802, grad_fn=<NegBackward0>)\n",
      "tensor(2.4801, grad_fn=<NegBackward0>)\n",
      "tensor(2.4800, grad_fn=<NegBackward0>)\n",
      "tensor(2.4799, grad_fn=<NegBackward0>)\n",
      "tensor(2.4798, grad_fn=<NegBackward0>)\n",
      "tensor(2.4798, grad_fn=<NegBackward0>)\n",
      "tensor(2.4797, grad_fn=<NegBackward0>)\n",
      "tensor(2.4796, grad_fn=<NegBackward0>)\n",
      "tensor(2.4795, grad_fn=<NegBackward0>)\n",
      "tensor(2.4794, grad_fn=<NegBackward0>)\n",
      "tensor(2.4794, grad_fn=<NegBackward0>)\n",
      "tensor(2.4793, grad_fn=<NegBackward0>)\n",
      "tensor(2.4792, grad_fn=<NegBackward0>)\n",
      "tensor(2.4791, grad_fn=<NegBackward0>)\n",
      "tensor(2.4791, grad_fn=<NegBackward0>)\n",
      "tensor(2.4790, grad_fn=<NegBackward0>)\n",
      "tensor(2.4789, grad_fn=<NegBackward0>)\n",
      "tensor(2.4788, grad_fn=<NegBackward0>)\n",
      "tensor(2.4788, grad_fn=<NegBackward0>)\n",
      "tensor(2.4787, grad_fn=<NegBackward0>)\n",
      "tensor(2.4786, grad_fn=<NegBackward0>)\n",
      "tensor(2.4786, grad_fn=<NegBackward0>)\n",
      "tensor(2.4785, grad_fn=<NegBackward0>)\n",
      "tensor(2.4784, grad_fn=<NegBackward0>)\n",
      "tensor(2.4783, grad_fn=<NegBackward0>)\n",
      "tensor(2.4783, grad_fn=<NegBackward0>)\n",
      "tensor(2.4782, grad_fn=<NegBackward0>)\n",
      "tensor(2.4781, grad_fn=<NegBackward0>)\n",
      "tensor(2.4781, grad_fn=<NegBackward0>)\n",
      "tensor(2.4780, grad_fn=<NegBackward0>)\n",
      "tensor(2.4779, grad_fn=<NegBackward0>)\n",
      "tensor(2.4778, grad_fn=<NegBackward0>)\n",
      "tensor(2.4778, grad_fn=<NegBackward0>)\n",
      "tensor(2.4777, grad_fn=<NegBackward0>)\n",
      "tensor(2.4776, grad_fn=<NegBackward0>)\n",
      "tensor(2.4776, grad_fn=<NegBackward0>)\n",
      "tensor(2.4775, grad_fn=<NegBackward0>)\n",
      "tensor(2.4774, grad_fn=<NegBackward0>)\n",
      "tensor(2.4774, grad_fn=<NegBackward0>)\n",
      "tensor(2.4773, grad_fn=<NegBackward0>)\n",
      "tensor(2.4772, grad_fn=<NegBackward0>)\n",
      "tensor(2.4772, grad_fn=<NegBackward0>)\n",
      "tensor(2.4771, grad_fn=<NegBackward0>)\n",
      "tensor(2.4771, grad_fn=<NegBackward0>)\n",
      "tensor(2.4770, grad_fn=<NegBackward0>)\n",
      "tensor(2.4769, grad_fn=<NegBackward0>)\n",
      "tensor(2.4769, grad_fn=<NegBackward0>)\n",
      "tensor(2.4768, grad_fn=<NegBackward0>)\n",
      "tensor(2.4767, grad_fn=<NegBackward0>)\n",
      "tensor(2.4767, grad_fn=<NegBackward0>)\n",
      "tensor(2.4766, grad_fn=<NegBackward0>)\n",
      "tensor(2.4766, grad_fn=<NegBackward0>)\n",
      "tensor(2.4765, grad_fn=<NegBackward0>)\n",
      "tensor(2.4764, grad_fn=<NegBackward0>)\n",
      "tensor(2.4764, grad_fn=<NegBackward0>)\n",
      "tensor(2.4763, grad_fn=<NegBackward0>)\n",
      "tensor(2.4762, grad_fn=<NegBackward0>)\n",
      "tensor(2.4762, grad_fn=<NegBackward0>)\n",
      "tensor(2.4761, grad_fn=<NegBackward0>)\n",
      "tensor(2.4761, grad_fn=<NegBackward0>)\n",
      "tensor(2.4760, grad_fn=<NegBackward0>)\n",
      "tensor(2.4760, grad_fn=<NegBackward0>)\n",
      "tensor(2.4759, grad_fn=<NegBackward0>)\n",
      "tensor(2.4758, grad_fn=<NegBackward0>)\n",
      "tensor(2.4758, grad_fn=<NegBackward0>)\n",
      "tensor(2.4757, grad_fn=<NegBackward0>)\n",
      "tensor(2.4757, grad_fn=<NegBackward0>)\n",
      "tensor(2.4756, grad_fn=<NegBackward0>)\n",
      "tensor(2.4755, grad_fn=<NegBackward0>)\n",
      "tensor(2.4755, grad_fn=<NegBackward0>)\n",
      "tensor(2.4754, grad_fn=<NegBackward0>)\n",
      "tensor(2.4754, grad_fn=<NegBackward0>)\n",
      "tensor(2.4753, grad_fn=<NegBackward0>)\n",
      "tensor(2.4753, grad_fn=<NegBackward0>)\n",
      "tensor(2.4752, grad_fn=<NegBackward0>)\n",
      "tensor(2.4752, grad_fn=<NegBackward0>)\n",
      "tensor(2.4751, grad_fn=<NegBackward0>)\n",
      "tensor(2.4750, grad_fn=<NegBackward0>)\n",
      "tensor(2.4750, grad_fn=<NegBackward0>)\n",
      "tensor(2.4749, grad_fn=<NegBackward0>)\n",
      "tensor(2.4749, grad_fn=<NegBackward0>)\n",
      "tensor(2.4748, grad_fn=<NegBackward0>)\n",
      "tensor(2.4748, grad_fn=<NegBackward0>)\n",
      "tensor(2.4747, grad_fn=<NegBackward0>)\n",
      "tensor(2.4747, grad_fn=<NegBackward0>)\n",
      "tensor(2.4746, grad_fn=<NegBackward0>)\n",
      "tensor(2.4746, grad_fn=<NegBackward0>)\n",
      "tensor(2.4745, grad_fn=<NegBackward0>)\n",
      "tensor(2.4745, grad_fn=<NegBackward0>)\n",
      "tensor(2.4744, grad_fn=<NegBackward0>)\n",
      "tensor(2.4744, grad_fn=<NegBackward0>)\n",
      "tensor(2.4743, grad_fn=<NegBackward0>)\n",
      "tensor(2.4743, grad_fn=<NegBackward0>)\n",
      "tensor(2.4742, grad_fn=<NegBackward0>)\n",
      "tensor(2.4742, grad_fn=<NegBackward0>)\n",
      "tensor(2.4741, grad_fn=<NegBackward0>)\n",
      "tensor(2.4741, grad_fn=<NegBackward0>)\n",
      "tensor(2.4740, grad_fn=<NegBackward0>)\n",
      "tensor(2.4740, grad_fn=<NegBackward0>)\n",
      "tensor(2.4739, grad_fn=<NegBackward0>)\n",
      "tensor(2.4739, grad_fn=<NegBackward0>)\n",
      "tensor(2.4738, grad_fn=<NegBackward0>)\n",
      "tensor(2.4738, grad_fn=<NegBackward0>)\n",
      "tensor(2.4737, grad_fn=<NegBackward0>)\n",
      "tensor(2.4737, grad_fn=<NegBackward0>)\n",
      "tensor(2.4736, grad_fn=<NegBackward0>)\n",
      "tensor(2.4736, grad_fn=<NegBackward0>)\n",
      "tensor(2.4735, grad_fn=<NegBackward0>)\n",
      "tensor(2.4735, grad_fn=<NegBackward0>)\n",
      "tensor(2.4734, grad_fn=<NegBackward0>)\n",
      "tensor(2.4734, grad_fn=<NegBackward0>)\n",
      "tensor(2.4733, grad_fn=<NegBackward0>)\n",
      "tensor(2.4733, grad_fn=<NegBackward0>)\n",
      "tensor(2.4733, grad_fn=<NegBackward0>)\n",
      "tensor(2.4732, grad_fn=<NegBackward0>)\n",
      "tensor(2.4732, grad_fn=<NegBackward0>)\n",
      "tensor(2.4731, grad_fn=<NegBackward0>)\n",
      "tensor(2.4731, grad_fn=<NegBackward0>)\n",
      "tensor(2.4730, grad_fn=<NegBackward0>)\n",
      "tensor(2.4730, grad_fn=<NegBackward0>)\n",
      "tensor(2.4729, grad_fn=<NegBackward0>)\n",
      "tensor(2.4729, grad_fn=<NegBackward0>)\n",
      "tensor(2.4728, grad_fn=<NegBackward0>)\n",
      "tensor(2.4728, grad_fn=<NegBackward0>)\n",
      "tensor(2.4728, grad_fn=<NegBackward0>)\n",
      "tensor(2.4727, grad_fn=<NegBackward0>)\n",
      "tensor(2.4727, grad_fn=<NegBackward0>)\n",
      "tensor(2.4726, grad_fn=<NegBackward0>)\n",
      "tensor(2.4726, grad_fn=<NegBackward0>)\n",
      "tensor(2.4725, grad_fn=<NegBackward0>)\n",
      "tensor(2.4725, grad_fn=<NegBackward0>)\n",
      "tensor(2.4725, grad_fn=<NegBackward0>)\n",
      "tensor(2.4724, grad_fn=<NegBackward0>)\n",
      "tensor(2.4724, grad_fn=<NegBackward0>)\n",
      "tensor(2.4723, grad_fn=<NegBackward0>)\n",
      "tensor(2.4723, grad_fn=<NegBackward0>)\n",
      "tensor(2.4723, grad_fn=<NegBackward0>)\n",
      "tensor(2.4722, grad_fn=<NegBackward0>)\n",
      "tensor(2.4722, grad_fn=<NegBackward0>)\n",
      "tensor(2.4721, grad_fn=<NegBackward0>)\n",
      "tensor(2.4721, grad_fn=<NegBackward0>)\n",
      "tensor(2.4720, grad_fn=<NegBackward0>)\n",
      "tensor(2.4720, grad_fn=<NegBackward0>)\n",
      "tensor(2.4720, grad_fn=<NegBackward0>)\n",
      "tensor(2.4719, grad_fn=<NegBackward0>)\n",
      "tensor(2.4719, grad_fn=<NegBackward0>)\n",
      "tensor(2.4718, grad_fn=<NegBackward0>)\n",
      "tensor(2.4718, grad_fn=<NegBackward0>)\n",
      "tensor(2.4718, grad_fn=<NegBackward0>)\n",
      "tensor(2.4717, grad_fn=<NegBackward0>)\n",
      "tensor(2.4717, grad_fn=<NegBackward0>)\n",
      "tensor(2.4716, grad_fn=<NegBackward0>)\n",
      "tensor(2.4716, grad_fn=<NegBackward0>)\n",
      "tensor(2.4716, grad_fn=<NegBackward0>)\n",
      "tensor(2.4715, grad_fn=<NegBackward0>)\n",
      "tensor(2.4715, grad_fn=<NegBackward0>)\n",
      "tensor(2.4715, grad_fn=<NegBackward0>)\n",
      "tensor(2.4714, grad_fn=<NegBackward0>)\n",
      "tensor(2.4714, grad_fn=<NegBackward0>)\n",
      "tensor(2.4713, grad_fn=<NegBackward0>)\n",
      "tensor(2.4713, grad_fn=<NegBackward0>)\n",
      "tensor(2.4713, grad_fn=<NegBackward0>)\n",
      "tensor(2.4712, grad_fn=<NegBackward0>)\n",
      "tensor(2.4712, grad_fn=<NegBackward0>)\n",
      "tensor(2.4712, grad_fn=<NegBackward0>)\n",
      "tensor(2.4711, grad_fn=<NegBackward0>)\n",
      "tensor(2.4711, grad_fn=<NegBackward0>)\n",
      "tensor(2.4710, grad_fn=<NegBackward0>)\n",
      "tensor(2.4710, grad_fn=<NegBackward0>)\n",
      "tensor(2.4710, grad_fn=<NegBackward0>)\n",
      "tensor(2.4709, grad_fn=<NegBackward0>)\n",
      "tensor(2.4709, grad_fn=<NegBackward0>)\n",
      "tensor(2.4709, grad_fn=<NegBackward0>)\n",
      "tensor(2.4708, grad_fn=<NegBackward0>)\n",
      "tensor(2.4708, grad_fn=<NegBackward0>)\n",
      "tensor(2.4708, grad_fn=<NegBackward0>)\n",
      "tensor(2.4707, grad_fn=<NegBackward0>)\n",
      "tensor(2.4707, grad_fn=<NegBackward0>)\n",
      "tensor(2.4707, grad_fn=<NegBackward0>)\n",
      "tensor(2.4706, grad_fn=<NegBackward0>)\n",
      "tensor(2.4706, grad_fn=<NegBackward0>)\n",
      "tensor(2.4705, grad_fn=<NegBackward0>)\n",
      "tensor(2.4705, grad_fn=<NegBackward0>)\n",
      "tensor(2.4705, grad_fn=<NegBackward0>)\n",
      "tensor(2.4704, grad_fn=<NegBackward0>)\n",
      "tensor(2.4704, grad_fn=<NegBackward0>)\n",
      "tensor(2.4704, grad_fn=<NegBackward0>)\n",
      "tensor(2.4703, grad_fn=<NegBackward0>)\n",
      "tensor(2.4703, grad_fn=<NegBackward0>)\n",
      "tensor(2.4703, grad_fn=<NegBackward0>)\n",
      "tensor(2.4702, grad_fn=<NegBackward0>)\n",
      "tensor(2.4702, grad_fn=<NegBackward0>)\n",
      "tensor(2.4702, grad_fn=<NegBackward0>)\n",
      "tensor(2.4701, grad_fn=<NegBackward0>)\n",
      "tensor(2.4701, grad_fn=<NegBackward0>)\n",
      "tensor(2.4701, grad_fn=<NegBackward0>)\n",
      "tensor(2.4700, grad_fn=<NegBackward0>)\n",
      "tensor(2.4700, grad_fn=<NegBackward0>)\n",
      "tensor(2.4700, grad_fn=<NegBackward0>)\n",
      "tensor(2.4699, grad_fn=<NegBackward0>)\n",
      "tensor(2.4699, grad_fn=<NegBackward0>)\n",
      "tensor(2.4699, grad_fn=<NegBackward0>)\n",
      "tensor(2.4699, grad_fn=<NegBackward0>)\n",
      "tensor(2.4698, grad_fn=<NegBackward0>)\n",
      "tensor(2.4698, grad_fn=<NegBackward0>)\n",
      "tensor(2.4698, grad_fn=<NegBackward0>)\n",
      "tensor(2.4697, grad_fn=<NegBackward0>)\n",
      "tensor(2.4697, grad_fn=<NegBackward0>)\n",
      "tensor(2.4697, grad_fn=<NegBackward0>)\n",
      "tensor(2.4696, grad_fn=<NegBackward0>)\n",
      "tensor(2.4696, grad_fn=<NegBackward0>)\n",
      "tensor(2.4696, grad_fn=<NegBackward0>)\n",
      "tensor(2.4695, grad_fn=<NegBackward0>)\n",
      "tensor(2.4695, grad_fn=<NegBackward0>)\n",
      "tensor(2.4695, grad_fn=<NegBackward0>)\n",
      "tensor(2.4694, grad_fn=<NegBackward0>)\n",
      "tensor(2.4694, grad_fn=<NegBackward0>)\n",
      "tensor(2.4694, grad_fn=<NegBackward0>)\n",
      "tensor(2.4694, grad_fn=<NegBackward0>)\n",
      "tensor(2.4693, grad_fn=<NegBackward0>)\n",
      "tensor(2.4693, grad_fn=<NegBackward0>)\n",
      "tensor(2.4693, grad_fn=<NegBackward0>)\n",
      "tensor(2.4692, grad_fn=<NegBackward0>)\n",
      "tensor(2.4692, grad_fn=<NegBackward0>)\n",
      "tensor(2.4692, grad_fn=<NegBackward0>)\n",
      "tensor(2.4692, grad_fn=<NegBackward0>)\n",
      "tensor(2.4691, grad_fn=<NegBackward0>)\n",
      "tensor(2.4691, grad_fn=<NegBackward0>)\n",
      "tensor(2.4691, grad_fn=<NegBackward0>)\n",
      "tensor(2.4690, grad_fn=<NegBackward0>)\n",
      "tensor(2.4690, grad_fn=<NegBackward0>)\n",
      "tensor(2.4690, grad_fn=<NegBackward0>)\n",
      "tensor(2.4689, grad_fn=<NegBackward0>)\n",
      "tensor(2.4689, grad_fn=<NegBackward0>)\n",
      "tensor(2.4689, grad_fn=<NegBackward0>)\n",
      "tensor(2.4689, grad_fn=<NegBackward0>)\n",
      "tensor(2.4688, grad_fn=<NegBackward0>)\n",
      "tensor(2.4688, grad_fn=<NegBackward0>)\n",
      "tensor(2.4688, grad_fn=<NegBackward0>)\n",
      "tensor(2.4688, grad_fn=<NegBackward0>)\n",
      "tensor(2.4687, grad_fn=<NegBackward0>)\n",
      "tensor(2.4687, grad_fn=<NegBackward0>)\n",
      "tensor(2.4687, grad_fn=<NegBackward0>)\n",
      "tensor(2.4686, grad_fn=<NegBackward0>)\n",
      "tensor(2.4686, grad_fn=<NegBackward0>)\n",
      "tensor(2.4686, grad_fn=<NegBackward0>)\n",
      "tensor(2.4686, grad_fn=<NegBackward0>)\n",
      "tensor(2.4685, grad_fn=<NegBackward0>)\n",
      "tensor(2.4685, grad_fn=<NegBackward0>)\n",
      "tensor(2.4685, grad_fn=<NegBackward0>)\n",
      "tensor(2.4685, grad_fn=<NegBackward0>)\n",
      "tensor(2.4684, grad_fn=<NegBackward0>)\n",
      "tensor(2.4684, grad_fn=<NegBackward0>)\n",
      "tensor(2.4684, grad_fn=<NegBackward0>)\n",
      "tensor(2.4683, grad_fn=<NegBackward0>)\n",
      "tensor(2.4683, grad_fn=<NegBackward0>)\n",
      "tensor(2.4683, grad_fn=<NegBackward0>)\n",
      "tensor(2.4683, grad_fn=<NegBackward0>)\n",
      "tensor(2.4682, grad_fn=<NegBackward0>)\n",
      "tensor(2.4682, grad_fn=<NegBackward0>)\n",
      "tensor(2.4682, grad_fn=<NegBackward0>)\n",
      "tensor(2.4682, grad_fn=<NegBackward0>)\n",
      "tensor(2.4681, grad_fn=<NegBackward0>)\n",
      "tensor(2.4681, grad_fn=<NegBackward0>)\n",
      "tensor(2.4681, grad_fn=<NegBackward0>)\n",
      "tensor(2.4681, grad_fn=<NegBackward0>)\n",
      "tensor(2.4680, grad_fn=<NegBackward0>)\n",
      "tensor(2.4680, grad_fn=<NegBackward0>)\n",
      "tensor(2.4680, grad_fn=<NegBackward0>)\n",
      "tensor(2.4680, grad_fn=<NegBackward0>)\n",
      "tensor(2.4679, grad_fn=<NegBackward0>)\n",
      "tensor(2.4679, grad_fn=<NegBackward0>)\n",
      "tensor(2.4679, grad_fn=<NegBackward0>)\n",
      "tensor(2.4679, grad_fn=<NegBackward0>)\n",
      "tensor(2.4678, grad_fn=<NegBackward0>)\n",
      "tensor(2.4678, grad_fn=<NegBackward0>)\n",
      "tensor(2.4678, grad_fn=<NegBackward0>)\n",
      "tensor(2.4678, grad_fn=<NegBackward0>)\n",
      "tensor(2.4677, grad_fn=<NegBackward0>)\n",
      "tensor(2.4677, grad_fn=<NegBackward0>)\n",
      "tensor(2.4677, grad_fn=<NegBackward0>)\n",
      "tensor(2.4677, grad_fn=<NegBackward0>)\n",
      "tensor(2.4676, grad_fn=<NegBackward0>)\n",
      "tensor(2.4676, grad_fn=<NegBackward0>)\n",
      "tensor(2.4676, grad_fn=<NegBackward0>)\n",
      "tensor(2.4676, grad_fn=<NegBackward0>)\n",
      "tensor(2.4675, grad_fn=<NegBackward0>)\n",
      "tensor(2.4675, grad_fn=<NegBackward0>)\n",
      "tensor(2.4675, grad_fn=<NegBackward0>)\n",
      "tensor(2.4675, grad_fn=<NegBackward0>)\n",
      "tensor(2.4675, grad_fn=<NegBackward0>)\n",
      "tensor(2.4674, grad_fn=<NegBackward0>)\n",
      "tensor(2.4674, grad_fn=<NegBackward0>)\n",
      "tensor(2.4674, grad_fn=<NegBackward0>)\n",
      "tensor(2.4674, grad_fn=<NegBackward0>)\n",
      "tensor(2.4673, grad_fn=<NegBackward0>)\n",
      "tensor(2.4673, grad_fn=<NegBackward0>)\n",
      "tensor(2.4673, grad_fn=<NegBackward0>)\n",
      "tensor(2.4673, grad_fn=<NegBackward0>)\n",
      "tensor(2.4672, grad_fn=<NegBackward0>)\n",
      "tensor(2.4672, grad_fn=<NegBackward0>)\n",
      "tensor(2.4672, grad_fn=<NegBackward0>)\n",
      "tensor(2.4672, grad_fn=<NegBackward0>)\n",
      "tensor(2.4672, grad_fn=<NegBackward0>)\n",
      "tensor(2.4671, grad_fn=<NegBackward0>)\n",
      "tensor(2.4671, grad_fn=<NegBackward0>)\n",
      "tensor(2.4671, grad_fn=<NegBackward0>)\n",
      "tensor(2.4671, grad_fn=<NegBackward0>)\n",
      "tensor(2.4670, grad_fn=<NegBackward0>)\n",
      "tensor(2.4670, grad_fn=<NegBackward0>)\n",
      "tensor(2.4670, grad_fn=<NegBackward0>)\n",
      "tensor(2.4670, grad_fn=<NegBackward0>)\n",
      "tensor(2.4670, grad_fn=<NegBackward0>)\n",
      "tensor(2.4669, grad_fn=<NegBackward0>)\n",
      "tensor(2.4669, grad_fn=<NegBackward0>)\n",
      "tensor(2.4669, grad_fn=<NegBackward0>)\n",
      "tensor(2.4669, grad_fn=<NegBackward0>)\n",
      "tensor(2.4669, grad_fn=<NegBackward0>)\n",
      "tensor(2.4668, grad_fn=<NegBackward0>)\n",
      "tensor(2.4668, grad_fn=<NegBackward0>)\n",
      "tensor(2.4668, grad_fn=<NegBackward0>)\n",
      "tensor(2.4668, grad_fn=<NegBackward0>)\n",
      "tensor(2.4667, grad_fn=<NegBackward0>)\n",
      "tensor(2.4667, grad_fn=<NegBackward0>)\n",
      "tensor(2.4667, grad_fn=<NegBackward0>)\n",
      "tensor(2.4667, grad_fn=<NegBackward0>)\n",
      "tensor(2.4667, grad_fn=<NegBackward0>)\n",
      "tensor(2.4666, grad_fn=<NegBackward0>)\n",
      "tensor(2.4666, grad_fn=<NegBackward0>)\n",
      "tensor(2.4666, grad_fn=<NegBackward0>)\n",
      "tensor(2.4666, grad_fn=<NegBackward0>)\n",
      "tensor(2.4666, grad_fn=<NegBackward0>)\n",
      "tensor(2.4665, grad_fn=<NegBackward0>)\n",
      "tensor(2.4665, grad_fn=<NegBackward0>)\n",
      "tensor(2.4665, grad_fn=<NegBackward0>)\n",
      "tensor(2.4665, grad_fn=<NegBackward0>)\n",
      "tensor(2.4665, grad_fn=<NegBackward0>)\n",
      "tensor(2.4664, grad_fn=<NegBackward0>)\n",
      "tensor(2.4664, grad_fn=<NegBackward0>)\n",
      "tensor(2.4664, grad_fn=<NegBackward0>)\n",
      "tensor(2.4664, grad_fn=<NegBackward0>)\n",
      "tensor(2.4664, grad_fn=<NegBackward0>)\n",
      "tensor(2.4663, grad_fn=<NegBackward0>)\n",
      "tensor(2.4663, grad_fn=<NegBackward0>)\n",
      "tensor(2.4663, grad_fn=<NegBackward0>)\n",
      "tensor(2.4663, grad_fn=<NegBackward0>)\n",
      "tensor(2.4663, grad_fn=<NegBackward0>)\n",
      "tensor(2.4662, grad_fn=<NegBackward0>)\n",
      "tensor(2.4662, grad_fn=<NegBackward0>)\n",
      "tensor(2.4662, grad_fn=<NegBackward0>)\n",
      "tensor(2.4662, grad_fn=<NegBackward0>)\n",
      "tensor(2.4662, grad_fn=<NegBackward0>)\n",
      "tensor(2.4661, grad_fn=<NegBackward0>)\n",
      "tensor(2.4661, grad_fn=<NegBackward0>)\n",
      "tensor(2.4661, grad_fn=<NegBackward0>)\n",
      "tensor(2.4661, grad_fn=<NegBackward0>)\n",
      "tensor(2.4661, grad_fn=<NegBackward0>)\n",
      "tensor(2.4660, grad_fn=<NegBackward0>)\n",
      "tensor(2.4660, grad_fn=<NegBackward0>)\n",
      "tensor(2.4660, grad_fn=<NegBackward0>)\n",
      "tensor(2.4660, grad_fn=<NegBackward0>)\n",
      "tensor(2.4660, grad_fn=<NegBackward0>)\n",
      "tensor(2.4660, grad_fn=<NegBackward0>)\n",
      "tensor(2.4659, grad_fn=<NegBackward0>)\n",
      "tensor(2.4659, grad_fn=<NegBackward0>)\n",
      "tensor(2.4659, grad_fn=<NegBackward0>)\n",
      "tensor(2.4659, grad_fn=<NegBackward0>)\n",
      "tensor(2.4659, grad_fn=<NegBackward0>)\n",
      "tensor(2.4658, grad_fn=<NegBackward0>)\n",
      "tensor(2.4658, grad_fn=<NegBackward0>)\n",
      "tensor(2.4658, grad_fn=<NegBackward0>)\n",
      "tensor(2.4658, grad_fn=<NegBackward0>)\n",
      "tensor(2.4658, grad_fn=<NegBackward0>)\n",
      "tensor(2.4658, grad_fn=<NegBackward0>)\n",
      "tensor(2.4657, grad_fn=<NegBackward0>)\n",
      "tensor(2.4657, grad_fn=<NegBackward0>)\n",
      "tensor(2.4657, grad_fn=<NegBackward0>)\n",
      "tensor(2.4657, grad_fn=<NegBackward0>)\n",
      "tensor(2.4657, grad_fn=<NegBackward0>)\n",
      "tensor(2.4656, grad_fn=<NegBackward0>)\n",
      "tensor(2.4656, grad_fn=<NegBackward0>)\n",
      "tensor(2.4656, grad_fn=<NegBackward0>)\n",
      "tensor(2.4656, grad_fn=<NegBackward0>)\n",
      "tensor(2.4656, grad_fn=<NegBackward0>)\n",
      "tensor(2.4656, grad_fn=<NegBackward0>)\n",
      "tensor(2.4655, grad_fn=<NegBackward0>)\n",
      "tensor(2.4655, grad_fn=<NegBackward0>)\n",
      "tensor(2.4655, grad_fn=<NegBackward0>)\n",
      "tensor(2.4655, grad_fn=<NegBackward0>)\n",
      "tensor(2.4655, grad_fn=<NegBackward0>)\n",
      "tensor(2.4655, grad_fn=<NegBackward0>)\n",
      "tensor(2.4654, grad_fn=<NegBackward0>)\n",
      "tensor(2.4654, grad_fn=<NegBackward0>)\n",
      "tensor(2.4654, grad_fn=<NegBackward0>)\n",
      "tensor(2.4654, grad_fn=<NegBackward0>)\n",
      "tensor(2.4654, grad_fn=<NegBackward0>)\n",
      "tensor(2.4654, grad_fn=<NegBackward0>)\n",
      "tensor(2.4653, grad_fn=<NegBackward0>)\n",
      "tensor(2.4653, grad_fn=<NegBackward0>)\n",
      "tensor(2.4653, grad_fn=<NegBackward0>)\n",
      "tensor(2.4653, grad_fn=<NegBackward0>)\n",
      "tensor(2.4653, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4651, grad_fn=<NegBackward0>)\n",
      "tensor(2.4651, grad_fn=<NegBackward0>)\n",
      "tensor(2.4651, grad_fn=<NegBackward0>)\n",
      "tensor(2.4651, grad_fn=<NegBackward0>)\n",
      "tensor(2.4651, grad_fn=<NegBackward0>)\n",
      "tensor(2.4651, grad_fn=<NegBackward0>)\n",
      "tensor(2.4650, grad_fn=<NegBackward0>)\n",
      "tensor(2.4650, grad_fn=<NegBackward0>)\n",
      "tensor(2.4650, grad_fn=<NegBackward0>)\n",
      "tensor(2.4650, grad_fn=<NegBackward0>)\n",
      "tensor(2.4650, grad_fn=<NegBackward0>)\n",
      "tensor(2.4650, grad_fn=<NegBackward0>)\n",
      "tensor(2.4649, grad_fn=<NegBackward0>)\n",
      "tensor(2.4649, grad_fn=<NegBackward0>)\n",
      "tensor(2.4649, grad_fn=<NegBackward0>)\n",
      "tensor(2.4649, grad_fn=<NegBackward0>)\n",
      "tensor(2.4649, grad_fn=<NegBackward0>)\n",
      "tensor(2.4649, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4648, grad_fn=<NegBackward0>)\n",
      "tensor(2.4647, grad_fn=<NegBackward0>)\n",
      "tensor(2.4647, grad_fn=<NegBackward0>)\n",
      "tensor(2.4647, grad_fn=<NegBackward0>)\n",
      "tensor(2.4647, grad_fn=<NegBackward0>)\n",
      "tensor(2.4647, grad_fn=<NegBackward0>)\n",
      "tensor(2.4647, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4646, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4644, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4643, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4642, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4641, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4640, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4639, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4638, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4637, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4636, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4635, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4634, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4633, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4632, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4631, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4628, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4627, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4626, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4625, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4624, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4623, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4622, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4621, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4620, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4619, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4618, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4617, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4616, grad_fn=<NegBackward0>)\n",
      "tensor(2.4615, grad_fn=<NegBackward0>)\n",
      "tensor(2.4615, grad_fn=<NegBackward0>)\n",
      "tensor(2.4615, grad_fn=<NegBackward0>)\n",
      "tensor(2.4615, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#gradient descent\n",
    "for i in range(1000):\n",
    "    # forward pass\n",
    "    logits=X @ W\n",
    "    counts=logits.exp()\n",
    "    probs=counts/counts.sum(1,keepdim=True)\n",
    "    loss=-probs[torch.arange(num),ys].log().mean()\n",
    "    #backward pass\n",
    "    W.grad=None\n",
    "    loss.backward()\n",
    "    #update weights based off backward prop\n",
    "    W.data+=-10*W.grad\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0123, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[5,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mon.\n",
      "brei.\n",
      "eemchivign.\n",
      "killaka.\n",
      "y.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out=[]\n",
    "    ix=0\n",
    "    while True:\n",
    "        xenc=torch.nn.functional.one_hot(torch.tensor([ix]),num_classes=27).float()\n",
    "        logits=xenc@W\n",
    "        counts=logits.exp()\n",
    "        p=counts/counts.sum(1,keepdim=True)\n",
    "\n",
    "        ix=torch.multinomial(p,num_samples=1,replacement=True).item()\n",
    "        out.append(itos[ix])\n",
    "        if(ix==0):\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying sequential api of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.nn.Sequential(\n",
    "    torch.nn.Linear(27,27),\n",
    "    # torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion=torch.nn.NLLLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.nn.functional.one_hot(xs,num_classes=27).float()\n",
    "Y=torch.nn.functional.one_hot(ys,num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[torch.arange(num),ys].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0358)\n",
      "tensor(-0.0361)\n",
      "tensor(-0.0363)\n",
      "tensor(-0.0366)\n",
      "tensor(-0.0369)\n",
      "tensor(-0.0371)\n",
      "tensor(-0.0374)\n",
      "tensor(-0.0377)\n",
      "tensor(-0.0379)\n",
      "tensor(-0.0382)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    logits=model(X)\n",
    "    counts=logits.exp()\n",
    "    probs=counts/counts.sum(1,keepdim=True)\n",
    "    num=ys.nelement()\n",
    "    output=probs[torch.arange(num),ys]\n",
    "    print(output)\n",
    "    print(ys)\n",
    "    loss=criterion(output,ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xofszsxkohxxxabjqantpnotofqattutncxsppivnkcpymnxlqifvflyiqkmwtexpbhmxl.\n",
      "egvkaypoethv.\n",
      "lyeuxigjwftrmltffgnf.\n",
      "tcnylanixfsgpfwybuzhylh.\n",
      "foexjztksp.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out=[]\n",
    "    ix=0\n",
    "    while True:\n",
    "        xenc=torch.nn.functional.one_hot(torch.tensor([ix]),num_classes=27).float()\n",
    "        logits=model(xenc)\n",
    "        counts=logits.exp()\n",
    "        probs=counts/counts.sum(1,keepdim=True)\n",
    "        ix=torch.multinomial(probs,num_samples=1,replacement=True).item()\n",
    "        out.append(itos[ix])\n",
    "        if(ix==0):\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
